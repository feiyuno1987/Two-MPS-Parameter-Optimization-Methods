/*
 *             Parameter Optimize Method based on GLCM Texture Feature for MPS
 *     
 *     Deep convolution neural network is used to identify and distinguish the characteristics of 
 * reservoir model, so as to optimize the modeling parameters. 
 * 
 * Parameter optimization is proposed based on two intuitive assumptions. 
 * (1) For any MPS, if the random seed is not considered, there is a one-to-one correspondence 
 *     between the characteristics of the realizations and modeling parameters; If the impact of 
 *     random seeds is considered, there is a one-to-one relationship between the statistical data
 *     of realizations characteristics (such as mathematical expectation) and modeling parameters; 
 * (2) When the values of modeling parameters increase or decrease, the features of stochastic 
 *     realizations change gradually, not suddenly. Based on the above assumptions, a set of ordered
 *     modeling parameters are used to simulate a set of realizations, and the values of parameters
 *     are used as labels of all realizations. Then, the realizations generated by two adjacent 
 *     parameters are combined together. Some realizations are selected as samples for deep learning
 *     training, and the rest are used to test the accuracy of recognition. The recognition accuracy
 *     is associated with the modeling parameter value, and then the transitional parameter between
 *     "recognizable" and "unrecognizable" is selected from the relationship curve as the optimal parameter. 
 * 
 * usage:
 *     The program of this method uses ML.NET framework and TensorFlow convolution neural network as 
 *     a tool to train the realizations.When using this program, you should pay attention to the 
 *     configuration file path. 
 *     
 *     Folder AssetsFolder : remain unchanged
 *     SavePath : remain unchanged
 *     path_realizations : Modify to target folder
 *     
 *
 * Version: 1.0
 * Author:  Siyu Yu
 * Email:   siyuyu@yangtzeu.edu.cn (or 573315294@qq.com)
 * Date:    9 Dec 2020
 */

using Microsoft.ML;
using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;

namespace DeepLearning_Method
{
    class Program
    {
        public static readonly string AssetsFolder = @"..\..\..\..\..\ML_Assets";
        public static readonly string SavePath = @$"{AssetsFolder}\ImageClassification";
        public static string path_realizations = @"..\..\..\..\..\demo data\largetrain_101 [template radius MG3]\realizations";
        public static readonly string inceptionPb = Path.Combine(AssetsFolder, "TensorFlow", "tensorflow_inception_graph.pb");
        public static int SamplingNumber = 1;

        //Setting for Image Net
        private struct ImageNetSettings
        {
            public const int imageHeight = 224;
            public const int imageWidth = 224;
            public const float mean = 117;
            public const float scale = 1;
            public const bool channelsLast = true;
        }

        static void Main(string[] args)
        {
            System.Console.WriteLine();
            System.Console.WriteLine("* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *");
            System.Console.WriteLine("* An Experiment on recognition accuracy of Two adjacent parameter realizations based on deep learning *");
            System.Console.WriteLine("*          Version:1.0     Author: Siyu Yu    Date: 9 Dec 2020     Email: 573315294@qq.com            *");
            System.Console.WriteLine("* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *");

            System.Console.WriteLine();
            System.Console.WriteLine("--------- Pretreatment ---------");
            Pretreatment();

            System.Console.WriteLine();
            System.Console.WriteLine("--------- TrainingAndEvaluate ---------");
            TrainingAndEvaluate();
        }

        static void Pretreatment()
        {
            Pretreatment_ImageFolder.Process(path_realizations);
        }

        //Train in batch and then test the accuracy of neural network. 
        //Calculate the precision of each sampling training, and then calculate the average value. 
        static void TrainingAndEvaluate()
        {
            List<double> data = new List<double>();
            for (int i = 0; i < SamplingNumber; i++)
            {
                string TrainDataFolder = Path.Combine(AssetsFolder, "ImageClassification", $"train{i}");
                string TrainTagsPath = Path.Combine(AssetsFolder, "ImageClassification", $"train_tags{i}.tsv");

                MLContext mlContext = new MLContext(seed: 1);

                // STEP 1: Prepare data
                var fulldata = mlContext.Data.LoadFromTextFile<ImageNetData>(path: TrainTagsPath, separatorChar: '\t', hasHeader: false);

                var trainTestData = mlContext.Data.TrainTestSplit(fulldata, testFraction: 0.5);
                var trainData = trainTestData.TrainSet;
                var testData = trainTestData.TestSet;

                // STEP 2：Create a learning pipeline
                var pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: "LabelTokey", inputColumnName: "Label")
                    .Append(mlContext.Transforms.LoadImages(outputColumnName: "input", imageFolder: TrainDataFolder, inputColumnName: nameof(ImageNetData.ImagePath)))
                    .Append(mlContext.Transforms.ResizeImages(outputColumnName: "input", imageWidth: ImageNetSettings.imageWidth, imageHeight: ImageNetSettings.imageHeight, inputColumnName: "input"))
                    .Append(mlContext.Transforms.ExtractPixels(outputColumnName: "input", interleavePixelColors: ImageNetSettings.channelsLast, offsetImage: ImageNetSettings.mean))
                    .Append(mlContext.Model.LoadTensorFlowModel(inceptionPb).ScoreTensorFlowModel(outputColumnNames: new[] { "softmax2_pre_activation" }, inputColumnNames: new[] { "input" }, addBatchDimensionInput: true))
                    .Append(mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(labelColumnName: "LabelTokey", featureColumnName: "softmax2_pre_activation"))
                    .Append(mlContext.Transforms.Conversion.MapKeyToValue("PredictedLabelValue", "PredictedLabel"))
                    .AppendCacheCheckpoint(mlContext);

                // STEP 3：Adjust the neural network model through training data
                ITransformer model = pipeline.Fit(trainData);

                // STEP 4：Evaluate model
                Console.WriteLine("===== Evaluate model =======");
                var evaData = model.Transform(testData);
                var metrics = mlContext.MulticlassClassification.Evaluate(evaData, labelColumnName: "LabelTokey", predictedLabelColumnName: "PredictedLabel");
                var MacroAccuracy = metrics.MacroAccuracy;
                Console.WriteLine($"the {i}-th accuracy is {MacroAccuracy}");
                data.Add(MacroAccuracy);
            }
            Console.WriteLine();
            Console.WriteLine($"the mean of accuracy with evaluate sample data = {data.Average()}");
            Console.ReadKey();
        }
    }
}
